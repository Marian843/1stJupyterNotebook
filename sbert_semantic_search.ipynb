{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Marian843/1stJupyterNotebook/blob/main/sbert_semantic_search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0XXGKB0rElt4"
      },
      "outputs": [],
      "source": [
        "'''from google.colab import files\n",
        "uploaded = files.upload()'''"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Import the Needed Libraries**"
      ],
      "metadata": {
        "id": "r8t91FEgTApa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3GV5jH2UGlPS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cae8905d-7639-49b3-e439-03102b8bd550"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "import spacy\n",
        "import unicodedata\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sentence_transformers import util\n",
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "from nltk.tokenize import sent_tokenize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zOQ-eaO0DUw"
      },
      "source": [
        "##**Load the Dataset**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "- This will load the dataset uploaded in Google Drive.\n",
        "- The dataset is from Kaggle.\n",
        "- The dataset is composed of title and its abstract from the paper of **Arxiv**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "oan8BZZmsblC",
        "outputId": "a705fa38-1a32-4032-ea7f-22789b491531"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  titles  \\\n",
              "0      Survey on Semantic Stereo Matching / Semantic ...   \n",
              "1      FUTURE-AI: Guiding Principles and Consensus Re...   \n",
              "2      Enforcing Mutual Consistency of Hard Regions f...   \n",
              "3      Parameter Decoupling Strategy for Semi-supervi...   \n",
              "4      Background-Foreground Segmentation for Interio...   \n",
              "...                                                  ...   \n",
              "51769  Hierarchically-coupled hidden Markov models fo...   \n",
              "51770                         Blinking Molecule Tracking   \n",
              "51771  Towards a Mathematical Foundation of Immunolog...   \n",
              "51772  A Semi-Automatic Graph-Based Approach for Dete...   \n",
              "51773  SparseCodePicking: feature extraction in mass ...   \n",
              "\n",
              "                                               summaries  \\\n",
              "0      Stereo matching is one of the widely used tech...   \n",
              "1      The recent advancements in artificial intellig...   \n",
              "2      In this paper, we proposed a novel mutual cons...   \n",
              "3      Consistency training has proven to be an advan...   \n",
              "4      To ensure safety in automated driving, the cor...   \n",
              "...                                                  ...   \n",
              "51769  We address the problem of analyzing sets of no...   \n",
              "51770  We discuss a method for tracking individual mo...   \n",
              "51771  We attempt to set a mathematical foundation of...   \n",
              "51772  Diffusion Tensor Imaging (DTI) allows estimati...   \n",
              "51773  Mass spectrometry (MS) is an important techniq...   \n",
              "\n",
              "                                                   terms  \n",
              "0                                     ['cs.CV', 'cs.LG']  \n",
              "1                            ['cs.CV', 'cs.AI', 'cs.LG']  \n",
              "2                                     ['cs.CV', 'cs.AI']  \n",
              "3                                              ['cs.CV']  \n",
              "4                                     ['cs.CV', 'cs.LG']  \n",
              "...                                                  ...  \n",
              "51769          ['stat.ML', 'physics.bio-ph', 'q-bio.QM']  \n",
              "51770                                 ['cs.CV', 'cs.DM']  \n",
              "51771                   ['stat.ML', 'cs.LG', 'q-bio.GN']  \n",
              "51772                                          ['cs.CV']  \n",
              "51773  ['stat.ML', 'physics.med-ph', 'stat.AP', 'stat...  \n",
              "\n",
              "[51774 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9bb32d13-8f42-49f9-96d0-7f239fc11a91\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>titles</th>\n",
              "      <th>summaries</th>\n",
              "      <th>terms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Survey on Semantic Stereo Matching / Semantic ...</td>\n",
              "      <td>Stereo matching is one of the widely used tech...</td>\n",
              "      <td>['cs.CV', 'cs.LG']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FUTURE-AI: Guiding Principles and Consensus Re...</td>\n",
              "      <td>The recent advancements in artificial intellig...</td>\n",
              "      <td>['cs.CV', 'cs.AI', 'cs.LG']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Enforcing Mutual Consistency of Hard Regions f...</td>\n",
              "      <td>In this paper, we proposed a novel mutual cons...</td>\n",
              "      <td>['cs.CV', 'cs.AI']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Parameter Decoupling Strategy for Semi-supervi...</td>\n",
              "      <td>Consistency training has proven to be an advan...</td>\n",
              "      <td>['cs.CV']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Background-Foreground Segmentation for Interio...</td>\n",
              "      <td>To ensure safety in automated driving, the cor...</td>\n",
              "      <td>['cs.CV', 'cs.LG']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51769</th>\n",
              "      <td>Hierarchically-coupled hidden Markov models fo...</td>\n",
              "      <td>We address the problem of analyzing sets of no...</td>\n",
              "      <td>['stat.ML', 'physics.bio-ph', 'q-bio.QM']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51770</th>\n",
              "      <td>Blinking Molecule Tracking</td>\n",
              "      <td>We discuss a method for tracking individual mo...</td>\n",
              "      <td>['cs.CV', 'cs.DM']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51771</th>\n",
              "      <td>Towards a Mathematical Foundation of Immunolog...</td>\n",
              "      <td>We attempt to set a mathematical foundation of...</td>\n",
              "      <td>['stat.ML', 'cs.LG', 'q-bio.GN']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51772</th>\n",
              "      <td>A Semi-Automatic Graph-Based Approach for Dete...</td>\n",
              "      <td>Diffusion Tensor Imaging (DTI) allows estimati...</td>\n",
              "      <td>['cs.CV']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51773</th>\n",
              "      <td>SparseCodePicking: feature extraction in mass ...</td>\n",
              "      <td>Mass spectrometry (MS) is an important techniq...</td>\n",
              "      <td>['stat.ML', 'physics.med-ph', 'stat.AP', 'stat...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>51774 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9bb32d13-8f42-49f9-96d0-7f239fc11a91')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9bb32d13-8f42-49f9-96d0-7f239fc11a91 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9bb32d13-8f42-49f9-96d0-7f239fc11a91');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-30ddc838-84e9-4808-ba46-089ce91d13a3\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-30ddc838-84e9-4808-ba46-089ce91d13a3')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-30ddc838-84e9-4808-ba46-089ce91d13a3 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_409a59e0-3663-438d-aeb3-ddca328a5a26\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_409a59e0-3663-438d-aeb3-ddca328a5a26 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 51774,\n  \"fields\": [\n    {\n      \"column\": \"titles\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 38972,\n        \"samples\": [\n          \"Sum-Product-Transform Networks: Exploiting Symmetries using Invertible Transformations\",\n          \"A Primal-Dual Subgradient Approachfor Fair Meta Learning\",\n          \"Adversarial Multi-Source Transfer Learning in Healthcare: Application to Glucose Prediction for Diabetic People\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summaries\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 38979,\n        \"samples\": [\n          \"Continual learning (CL) is a setting in which an agent has to learn from an\\nincoming stream of data during its entire lifetime. Although major advances\\nhave been made in the field, one recurring problem which remains unsolved is\\nthat of Catastrophic Forgetting (CF). While the issue has been extensively\\nstudied empirically, little attention has been paid from a theoretical angle.\\nIn this paper, we show that the impact of CF increases as two tasks\\nincreasingly align. We introduce a measure of task similarity called the NTK\\noverlap matrix which is at the core of CF. We analyze common projected gradient\\nalgorithms and demonstrate how they mitigate forgetting. Then, we propose a\\nvariant of Orthogonal Gradient Descent (OGD) which leverages structure of the\\ndata through Principal Component Analysis (PCA). Experiments support our\\ntheoretical findings and show how our method can help reduce CF on classical CL\\ndatasets.\",\n          \"Few-shot learning is a challenging task since only few instances are given\\nfor recognizing an unseen class. One way to alleviate this problem is to\\nacquire a strong inductive bias via meta-learning on similar tasks. In this\\npaper, we show that such inductive bias can be learned from a flat collection\\nof unlabeled images, and instantiated as transferable representations among\\nseen and unseen classes. Specifically, we propose a novel part-based\\nself-supervised representation learning scheme to learn transferable\\nrepresentations by maximizing the similarity of an image to its discriminative\\npart. To mitigate the overfitting in few-shot classification caused by data\\nscarcity, we further propose a part augmentation strategy by retrieving extra\\nimages from a base dataset. We conduct systematic studies on miniImageNet and\\ntieredImageNet benchmarks. Remarkably, our method yields impressive results,\\noutperforming the previous best unsupervised methods by 7.74% and 9.24% under\\n5-way 1-shot and 5-way 5-shot settings, which are comparable with\\nstate-of-the-art supervised methods.\",\n          \"Surgical instrument segmentation is extremely important for computer-assisted\\nsurgery. Different from common object segmentation, it is more challenging due\\nto the large illumination and scale variation caused by the special surgical\\nscenes. In this paper, we propose a novel bilinear attention network with\\nadaptive receptive field to solve these two challenges. For the illumination\\nvariation, the bilinear attention module can capture second-order statistics to\\nencode global contexts and semantic dependencies between local pixels. With\\nthem, semantic features in challenging areas can be inferred from their\\nneighbors and the distinction of various semantics can be boosted. For the\\nscale variation, our adaptive receptive field module aggregates multi-scale\\nfeatures and automatically fuses them with different weights. Specifically, it\\nencodes the semantic relationship between channels to emphasize feature maps\\nwith appropriate scales, changing the receptive field of subsequent\\nconvolutions. The proposed network achieves the best performance 97.47% mean\\nIOU on Cata7 and comes first place on EndoVis 2017 by 10.10% IOU overtaking\\nsecond-ranking method.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"terms\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3157,\n        \"samples\": [\n          \"['cs.LG', 'cs.CE', 'q-fin.ST', 'stat.ML']\",\n          \"['cs.LG', 'physics.comp-ph', 'physics.flu-dyn']\",\n          \"['cs.LG', 'cs.CV', 'math.AT']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/arxiv_data.csv')\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yoGBOth0FP_5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "072e67ed-d91c-4c42-9eb6-d441deea753d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: contractions in /usr/local/lib/python3.11/dist-packages (0.1.73)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.11/dist-packages (from contractions) (0.0.24)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.11/dist-packages (from textsearch>=0.0.21->contractions) (0.3.3)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.11/dist-packages (from textsearch>=0.0.21->contractions) (2.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk contractions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJkBh0TB0Tp-"
      },
      "source": [
        "##**Cleaning the Data**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "- Used a basic NLP cleaning pipeline while keeping in mind the SBERT model\n",
        "  - Sentence Tokenization\n",
        "  - Expand Contractions (*for example:* from don't → do not)\n",
        "  - Unicode Normalization\n",
        "  - Lowercase\n",
        "  - Link Removal (https://, www., .com)\n",
        "  - Non-word Removal\n",
        "  - Latin Abbreviations Removal (i.e., e.g., etc.)\n",
        "  - Extra whitespaces removal\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KgoIGh91BAsD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c116ca8c-b310-472a-967c-8ab983b62235"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ],
      "source": [
        "def clean_and_tokenize_text(text):\n",
        "    if not text or pd.isna(text):\n",
        "        return []\n",
        "\n",
        "    # Normalize unicode\n",
        "    text = unicodedata.normalize(\"NFKC\", text)\n",
        "\n",
        "    # Expand contractions (e.g., \"don't\" → \"do not\")\n",
        "    text = contractions.fix(text)\n",
        "\n",
        "    # Lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove URLs and emails\n",
        "    text = re.sub(r\"http\\S+|www\\.\\S+|\\S+@\\S+\", \"\", text)\n",
        "\n",
        "    # Remove non-word characters but keeping the punctuation\n",
        "    text = re.sub(r\"[^\\w\\s.,!?]\", \"\", text)\n",
        "\n",
        "    text = re.sub(r'\\b(e\\.g\\.|i\\.e\\.|etc\\.)', '', text, flags=re.IGNORECASE)\n",
        "\n",
        "    # Sentence tokenization\n",
        "    sentences = sent_tokenize(text)\n",
        "\n",
        "    # Remove extra whitespace and empty strings\n",
        "    cleaned_sentences = [re.sub(r\"\\s+\", \" \", s).strip() for s in sentences if s.strip()]\n",
        "\n",
        "    return cleaned_sentences\n",
        "\n",
        "df['cleaned_sentences'] = df.apply(\n",
        "    lambda row: clean_and_tokenize_text(f\"{row['titles']}. {row['summaries']}\"),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "df.to_csv(\"cleaned_sentences_output.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Load the SBERT Model and Generate Sentence Embeddings**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "It uses Sentence Transformers (also known as SBERT) library to convert the sentences into vector embeddings.\n",
        "\n",
        "The pre-trained SBERT model that is used is *all-MiniLM-L6-v2* which is much faster and efficient compared to other models."
      ],
      "metadata": {
        "id": "OvOK4YfZG5pj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QfkLe6OzjI5l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394,
          "referenced_widgets": [
            "02f50b7980a94239b128bab2dc1b6b8d",
            "9666031793e84b7792eb88ed7208db66",
            "ac5ed2535999429f9c5abb0820df8ae7",
            "5c8a498157024326914d654194db971b",
            "1bf95f2464fc4316bcc4127bdcd2626d",
            "f2e41c5d509f493986fe633e64e7bcc9",
            "56c2c8d356e24360b4531f1c9251eb03",
            "3b70b86f30a74abb83352508fcf4f8af",
            "4bdf8475fb034190ac81d847209794b1",
            "e392cfede1f1405ebbebe2fe6bdcb491",
            "7fb2c3f1386948a9b6d476ade8ad45c2",
            "eb1107b575344bc5a7096967411b342d"
          ]
        },
        "outputId": "c4862584-7d5c-419b-f6e9-a2b91a624880"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "02f50b7980a94239b128bab2dc1b6b8d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9666031793e84b7792eb88ed7208db66",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ac5ed2535999429f9c5abb0820df8ae7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5c8a498157024326914d654194db971b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1bf95f2464fc4316bcc4127bdcd2626d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f2e41c5d509f493986fe633e64e7bcc9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "56c2c8d356e24360b4531f1c9251eb03",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3b70b86f30a74abb83352508fcf4f8af",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4bdf8475fb034190ac81d847209794b1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e392cfede1f1405ebbebe2fe6bdcb491",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7fb2c3f1386948a9b6d476ade8ad45c2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eb1107b575344bc5a7096967411b342d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1618 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "df['joined_sentences'] = df['cleaned_sentences'].apply(lambda sents: \" \".join(sents))\n",
        "\n",
        "embeddings = model.encode(df['joined_sentences'].tolist(), show_progress_bar=True)\n",
        "\n",
        "np.save('sbert_embeddings.npy', embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Load the Saved Sentence Embeddings**"
      ],
      "metadata": {
        "id": "0dZ-wGLZGNBc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = np.load('sbert_embeddings.npy')"
      ],
      "metadata": {
        "id": "3WP-90Jp8szK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Skin tone detection using CNN\"\n",
        "query_embedding = model.encode(query, convert_to_numpy=True)\n",
        "\n",
        "hits = util.semantic_search(query_embedding, embeddings, top_k=5)[0]\n",
        "\n",
        "for hit in hits:\n",
        "    idx = hit['corpus_id']\n",
        "    score = hit['score']\n",
        "    print(f\"Score: {score:.4f}\")\n",
        "    print(\"Title:\", df.iloc[idx]['titles'])\n",
        "    print(\"Summary:\", df.iloc[idx]['summaries'])\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGUQTTdn8w1w",
        "outputId": "90054de0-b47e-449a-b5ea-638449fa0bb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: 0.6396\n",
            "Title: Estimating Skin Tone and Effects on Classification Performance in Dermatology Datasets\n",
            "Summary: Recent advances in computer vision and deep learning have led to\n",
            "breakthroughs in the development of automated skin image analysis. In\n",
            "particular, skin cancer classification models have achieved performance higher\n",
            "than trained expert dermatologists. However, no attempt has been made to\n",
            "evaluate the consistency in performance of machine learning models across\n",
            "populations with varying skin tones. In this paper, we present an approach to\n",
            "estimate skin tone in benchmark skin disease datasets, and investigate whether\n",
            "model performance is dependent on this measure. Specifically, we use individual\n",
            "typology angle (ITA) to approximate skin tone in dermatology datasets. We look\n",
            "at the distribution of ITA values to better understand skin color\n",
            "representation in two benchmark datasets: 1) the ISIC 2018 Challenge dataset, a\n",
            "collection of dermoscopic images of skin lesions for the detection of skin\n",
            "cancer, and 2) the SD-198 dataset, a collection of clinical images capturing a\n",
            "wide variety of skin diseases. To estimate ITA, we first develop segmentation\n",
            "models to isolate non-diseased areas of skin. We find that the majority of the\n",
            "data in the the two datasets have ITA values between 34.5{\\deg} and 48{\\deg},\n",
            "which are associated with lighter skin, and is consistent with\n",
            "under-representation of darker skinned populations in these datasets. We also\n",
            "find no measurable correlation between performance of machine learning model\n",
            "and ITA values, though more comprehensive data is needed for further\n",
            "validation.\n",
            "\n",
            "\n",
            "Score: 0.6224\n",
            "Title: Real-time Segmentation and Facial Skin Tones Grading\n",
            "Summary: Modern approaches for semantic segmention usually pay too much attention to\n",
            "the accuracy of the model, and therefore it is strongly recommended to\n",
            "introduce cumbersome backbones, which brings heavy computation burden and\n",
            "memory footprint. To alleviate this problem, we propose an efficient\n",
            "segmentation method based on deep convolutional neural networks (DCNNs) for the\n",
            "task of hair and facial skin segmentation, which achieving remarkable trade-off\n",
            "between speed and performance on three benchmark datasets. As far as we know,\n",
            "the accuracy of skin tones classification is usually unsatisfactory due to the\n",
            "influence of external environmental factors such as illumination and background\n",
            "noise. Therefore, we use the segmentated face to obtain a specific face area,\n",
            "and further exploit the color moment algorithm to extract its color features.\n",
            "Specifically, for a 224 x 224 standard input, using our high-resolution spatial\n",
            "detail information and low-resolution contextual information fusion network\n",
            "(HLNet), we achieve 90.73% Pixel Accuracy on Figaro1k dataset at over 16 FPS in\n",
            "the case of CPU environment. Additional experiments on CamVid dataset further\n",
            "confirm the universality of the proposed model. We further use masked color\n",
            "moment for skin tones grade evaluation and approximate 80% classification\n",
            "accuracy demonstrate the feasibility of the proposed scheme.Code is available\n",
            "at\n",
            "https://github.com/JACKYLUO1991/Face-skin-hair-segmentaiton-and-skin-color-evaluation.\n",
            "\n",
            "\n",
            "Score: 0.6224\n",
            "Title: Real-time Segmentation and Facial Skin Tones Grading\n",
            "Summary: Modern approaches for semantic segmention usually pay too much attention to\n",
            "the accuracy of the model, and therefore it is strongly recommended to\n",
            "introduce cumbersome backbones, which brings heavy computation burden and\n",
            "memory footprint. To alleviate this problem, we propose an efficient\n",
            "segmentation method based on deep convolutional neural networks (DCNNs) for the\n",
            "task of hair and facial skin segmentation, which achieving remarkable trade-off\n",
            "between speed and performance on three benchmark datasets. As far as we know,\n",
            "the accuracy of skin tones classification is usually unsatisfactory due to the\n",
            "influence of external environmental factors such as illumination and background\n",
            "noise. Therefore, we use the segmentated face to obtain a specific face area,\n",
            "and further exploit the color moment algorithm to extract its color features.\n",
            "Specifically, for a 224 x 224 standard input, using our high-resolution spatial\n",
            "detail information and low-resolution contextual information fusion network\n",
            "(HLNet), we achieve 90.73% Pixel Accuracy on Figaro1k dataset at over 16 FPS in\n",
            "the case of CPU environment. Additional experiments on CamVid dataset further\n",
            "confirm the universality of the proposed model. We further use masked color\n",
            "moment for skin tones grade evaluation and approximate 80% classification\n",
            "accuracy demonstrate the feasibility of the proposed scheme.Code is available\n",
            "at\n",
            "https://github.com/JACKYLUO1991/Face-skin-hair-segmentaiton-and-skin-color-evaluation.\n",
            "\n",
            "\n",
            "Score: 0.6199\n",
            "Title: Domain adaptation for holistic skin detection\n",
            "Summary: Human skin detection in images is a widely studied topic of Computer Vision\n",
            "for which it is commonly accepted that analysis of pixel color or local patches\n",
            "may suffice. This is because skin regions appear to be relatively uniform and\n",
            "many argue that there is a small chromatic variation among different samples.\n",
            "However, we found that there are strong biases in the datasets commonly used to\n",
            "train or tune skin detection methods. Furthermore, the lack of contextual\n",
            "information may hinder the performance of local approaches. In this paper we\n",
            "present a comprehensive evaluation of holistic and local Convolutional Neural\n",
            "Network (CNN) approaches on in-domain and cross-domain experiments and compare\n",
            "with state-of-the-art pixel-based approaches. We also propose a combination of\n",
            "inductive transfer learning and unsupervised domain adaptation methods, which\n",
            "are evaluated on different domains under several amounts of labelled data\n",
            "availability. We show a clear superiority of CNN over pixel-based approaches\n",
            "even without labelled training samples on the target domain. Furthermore, we\n",
            "provide experimental support for the counter-intuitive superiority of holistic\n",
            "over local approaches for human skin detection.\n",
            "\n",
            "\n",
            "Score: 0.6199\n",
            "Title: Domain adaptation for holistic skin detection\n",
            "Summary: Human skin detection in images is a widely studied topic of Computer Vision\n",
            "for which it is commonly accepted that analysis of pixel color or local patches\n",
            "may suffice. This is because skin regions appear to be relatively uniform and\n",
            "many argue that there is a small chromatic variation among different samples.\n",
            "However, we found that there are strong biases in the datasets commonly used to\n",
            "train or tune skin detection methods. Furthermore, the lack of contextual\n",
            "information may hinder the performance of local approaches. In this paper we\n",
            "present a comprehensive evaluation of holistic and local Convolutional Neural\n",
            "Network (CNN) approaches on in-domain and cross-domain experiments and compare\n",
            "with state-of-the-art pixel-based approaches. We also propose a combination of\n",
            "inductive transfer learning and unsupervised domain adaptation methods, which\n",
            "are evaluated on different domains under several amounts of labelled data\n",
            "availability. We show a clear superiority of CNN over pixel-based approaches\n",
            "even without labelled training samples on the target domain. Furthermore, we\n",
            "provide experimental support for the counter-intuitive superiority of holistic\n",
            "over local approaches for human skin detection.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4RfOpakiXtEA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}